## 面向人脸识别场景的深度学习模型测试技术过程分析报告

### 图片预处理阶段



### 训练模型代码设计

#### CNN原理

##### 1.卷积神经网络概述

​		卷积神经网络（Convolutional Neural Networks）是一种深度学习模型或类似于人工神经网络的多层感知器，常用来分析视觉图像。它的特殊性体现在两个方面。一方面，它的神经元间的连接是非全连接的；另一方面，同一层中某些神经元之间的连接的权重是共享的（即相同的）。它的非全连接和权值共享的网络结构使之更类似于生物神经网络，降低了网络模型的复杂度（对于很难学习的深层结构来说，这是非常重要的），减少了权值的数量。

##### 2.卷积神经网络的架构

![](https://box.nju.edu.cn/f/9291618fdd4a49e29c84/?dl=1)

##### 3.卷积神经网络的训练

​		神经网络用于模式识别的主流是有指导学习网络，无指导学习网络更多的是用于聚类分析。对于有指导的模式识别，由于任一样本的类别是已知的，样本在空间的分布不再是依据其自然分布倾向来划分，而是要根据同类样本在空间的分布及不同类样本之间的分离程度找一种适当的空间划分方法，或者找到一个分类边界，使得不同类样本分别位于不同的区域内。这就需要一个长时间且复杂的学习过程，不断调整用以划分样本空间的分类边界的位置，使尽可能少的样本被划分到非同类区域中。

​		卷积网络在本质上是一种输入到输出的映射，它能够学习大量的输入与输出之间的映射关系，而不需要任何输入和输出之间的精确的数学表达式，只要用已知的模式对卷积网络加以训练，网络就具有输入输出对之间的映射能力。卷积网络执行的是有导师训练，所以其样本集是由形如：（输入向量，理想输出向量）的向量对构成的。所有这些向量对，都应该是来源于网络即将模拟的系统的实际“运行”结果。它们可以是从实际运行系统中采集来的。在开始训练前，所有的权都应该用一些不同的小随机数进行初始化。“小随机数”用来保证网络不会因权值过大而进入饱和状态，从而导致训练失败；“不同”用来保证网络可以正常地学习。实际上，如果用相同的数去初始化权矩阵，则网络无能力学习。

训练算法与传统的BP算法差不多。主要包括4步，这4步被分为两个阶段：

第一阶段，向前传播阶段：

​	a）从样本集中取一个样本(X,Yp)，将X输入网络；

​	b）计算相应的实际输出Op。

在此阶段，信息从输入层经过逐级的变换，传送到输出层。这个过程也是网络在完成训练后正常运行时执行的过程。在此过程中，网络执行的是计算（实际上就是输入与每层的权值矩阵相点乘，得到最后的输出结果）：

Op=Fn（…（F2（F1（XpW（1））W（2））…）W（n））

第二阶段，向后传播阶段：

​	a）算实际输出Op与相应的理想输出Yp的差；

​	b）按极小化误差的方法反向传播调整权矩阵。

##### 4.卷积神经网络的优点

​		卷积神经网络CNN主要用来识别位移、缩放及其他形式扭曲不变性的二维图形。由于CNN的特征检测层通过训练数据进行学习，所以在使用CNN时，避免了显式的特征抽取，而隐式地从训练数据中进行学习；再者由于同一特征映射面上的神经元权值相同，所以网络可以并行学习，这也是卷积网络相对于神经元彼此相连网络的优势之一。卷积神经网络以其局部权值共享的特殊结构在语音识别和图像处理方面有着独特的优越性，其布局更接近于实际的生物神经网络，权值共享降低了网络的复杂性，特别是多维输入向量的图像可以直接输入网络这一特点避免了特征提取和分类过程中数据重建的复杂度。

​		流的分类方式几乎都是基于统计特征的，这就意味着在进行分辨前必须提取某些特征。然而，显式的特征提取并不容易，在一些应用问题中也并非总是可靠的。卷积神经网络，它避免了显式的特征取样，隐式地从训练数据中进行学习。这使得卷积神经网络明显有别于其他基于神经网络的分类器，通过结构重组和减少权值将特征提取功能融合进多层感知器。它可以直接处理灰度图片，能够直接用于处理基于图像的分类。

​		卷积网络较一般神经网络在图像处理方面有如下优点： 

- 输入图像和网络的拓扑结构能很好的吻合；
- 特征提取和模式分类同时进行，并同时在训练中产生；
- 权重共享可以减少网络的训练参数，使神经网络结构变得更简单，适应性更强。

##### 5.卷积神经网络的问题

​		CNNs中的层间联系和空域信息的紧密关系，使其适于图像处理和理解。而且，其在自动提取图像的显著特征方面还表现出了比较优的性能。在一些例子当中，Gabor滤波器已经被使用在一个初始化预处理的步骤中，以达到模拟人类视觉系统对视觉刺激的响应。在目前大部分的工作中，研究者将CNNs应用到了多种机器学习问题中，包括人脸识别，文档分析和语言检测等。为了达到寻找视频中帧与帧之间的相干性的目的，目前CNNs通过一个时间相干性去训练，但这个不是CNNs特有的。

​		由于卷积神经网络采用BP网络相同的算法，所以采用现有BP网络就可以实现。开源的神经网络代码FAAN可以利用。这个开源的实现采用了一些代码优化技术，有双精度，单精度，定点运算三个不同的版本。

​		由于经典的BP网络是一个一维节点分布排列，而卷积神经网络是二维网络结构。所以，要把卷积神经网络的每一层，按照一定的顺序和规则映射为一维节点分布，然后，按照这个分布创建一个多层反向传播算法的网络结构，就可以按照一般的BP训练算法去学习网络参数。对于实际环境中新样本的预测，也采用BP算法中相同信号前向传递算法进行。

#### 设计思路

​		面向人脸识别场景的训练模型是基于CNN的的人脸识别模型而构建的。我们需要通过大量的训练数据训练我们的模型，因此首先要做的就是把训练数据准备好，并将其输入给CNN。在数据预处理阶段我们已经准备好了脸部图像的数据集，并对其进行了灰化处理，并且还需要将数据加载到内存，以方便输入给CNN。因此，第一步工作就是读取实例化后的DataSet类作为进行训练的数据源并将其加载进内存；通过调用python的keras库中的Sequential等函数建立一个CNN模型，抹平之后进行全链接、最后进行分类；在建立好CNN模型后，我们进行训练模型，通过编写模型训练的函数，并对其中的参数，例如epochs、batch_size等进行不断的调优，通过编写模型的评估函数以对模型的预测准确度进行结果分析。

#### 环境配置

人脸识别模型是基于CNN卷积神经网络而构建，整个项目的开发测试是在PyCharm中进行，在进行模型训练之前，需要进行tensorflow开发环境的配置。具体步骤如下：

1. 进入PyCharm中的Python Packages，搜索tensoflow、opencv、keras，点击install；

![](https://box.nju.edu.cn/f/2084ec6fef674ec2bb93/?dl=1)

2. 查看是否成功添加了相应的包。

![](https://box.nju.edu.cn/f/f4644a7bbff249d19084/?dl=1)

3. 借助Demo测试Tensorflow环境配置是否成功。

![](https://box.nju.edu.cn/f/d56f3b055e7d420a9a3d/?dl=1)

（得到输出结果，说明Tensorflow + pycharm环境配置完成）

![](https://box.nju.edu.cn/f/8d3310ecfd4345519194/?dl=1)

#### 代码实现

```python
from keras.optimizers import SGD
from keras.optimizers.optimizer_v1 import adam
from sklearn.svm._libsvm import predict_proba

from dataSet import DataSet
from keras import Sequential
from keras.models import load_model
from keras.layers import Dense,Activation,Convolution2D,MaxPooling2D,Flatten,Dropout
import numpy as np


# 建立一个基于CNN的人脸识别模型
class Model(object):
    FILE_PATH = "/FaceRecognition/twopeoplemodel.h5"  # 模型进行存储和读取的地方
    IMAGE_SIZE = 128  # 模型接受的人脸图片是128*128的

    def __init__(self):
        self.model = None

    # 读取实例化后的DataSet类作为进行训练的数据源
    def read_trainData(self, dataset):
        self.dataset = dataset

    # 建立一个CNN模型,抹平之后进行全链接、最后进行分类
    def build_model(self):
        self.model = Sequential()

        self.model.add(Convolution2D(filters=32, kernel_size=(5, 5), padding='same', input_shape=self.dataset.X_train.shape[1:]))
        self.model.add(Activation('relu'))
        self.model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2),padding='same'))
        self.model.add(Dropout(0.3))

        self.model.add(Convolution2D(filters=64, kernel_size=(5, 5), padding='same'))
        self.model.add(Activation('relu'))
        self.model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))
        self.model.add(Dropout(0.3))

        self.model.add(Convolution2D(filters=64, kernel_size=(5, 5), padding='same'))
        self.model.add(Activation('relu'))
        self.model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))
        self.model.add(Dropout(0.3))

        self.model.add(Convolution2D(filters=64, kernel_size=(5, 5), padding='same'))
        self.model.add(Activation('relu'))
        self.model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))
        self.model.add(Dropout(0.3))

        self.model.add(Flatten())
        self.model.add(Dense(512))
        self.model.add(Activation('relu'))
        self.model.add(Dropout(0.3))
        self.model.add(Dense(self.dataset.num_classes))
        self.model.add(Activation('softmax'))
        self.model.summary()

    # 进行模型训练的函数，具体的optimizer、loss可以进行不同选择
    def train_model(self):
        sgd=SGD(lr=0.01,decay=1e-6,momentum=0.9,nesterov=True)
        self.model.compile(
            optimizer=sgd,  # 有很多可选的optimizer，例如adam,Adagrad
            loss='categorical_crossentropy',  # 你可以选用squared_hinge作为loss看看哪个好
            metrics=['accuracy'])

        # epochs、batch_size为可调的参数，epochs为训练多少轮、batch_size为每次训练多少个样本
        self.model.fit(self.dataset.X_train, self.dataset.Y_train, epochs=20, batch_size=8)

    def evaluate_model(self):
        print('\nTesting---------------')
        loss, accuracy = self.model.evaluate(self.dataset.X_test, self.dataset.Y_test)

        print('test loss;', loss)
        print('test accuracy:', accuracy)

    def save(self, file_path=FILE_PATH):
        print('Model Saved.')
        self.model.save(file_path)

    def load(self, file_path=FILE_PATH):
        print('Model Loaded.')
        self.model = load_model(file_path)

    # 需要确保输入的img得是灰化之后（channel =1 )且 大小为IMAGE_SIZE的人脸图片
    def predict(self, img):
        img = img.reshape((1, 1, self.IMAGE_SIZE, self.IMAGE_SIZE))
        img = img.astype('float32')
        img = img / 255.0

        result = self.model.predict(img)  # 测算一下该img属于某个label的概率
        max_index = np.argmax(result)  # 找出概率最高的

        return max_index, result[0][max_index]  # 第一个 参数为概率最高的label的index,第二个参数为对应概率


if __name__ == '__main__':
    dataset = DataSet("../pictures/3_classes_pins_dataset")
    model = Model()
    model.read_trainData(dataset)
    model.build_model()
    model.train_model()
    model.evaluate_model()
    model.save()
```

### 

### 测试工具代码设计

#### 工具代码设计流程

1. 构建加载模型、测试模型的方法 test_model，获取测试结果
2. 构建处理文件名、获取标准答案的方法
3. 构建对比测试结果和答案，并计算准确率的方法
4. 构建格式化输出方法

#### 问题 & 思路

**问题1：如何获取测试数据集的标准答案？**

**思路**：测试数据集分两类图片，一种是应当被识别出对应人名的图片，另一种是“not find”即应该无法识别出人名的图片。凭借这一点，将第一种图片的名称规范化，并在 test_tool 中写一个读取并处理图片名称的方法，从而获取图片对应人名或“not find”

**问题2：当模型预测结果对应的概率较低时，得到的通常都是错误结果，如何尽可能提高准确率？**

**思路**：向 test_model 方法传入一个测试阈值变量，低于这个阈值的结果全部筛选掉，设置为“not_find”（无法识别）

**问题3：依据概率对预测结果进行筛选，会对准确率的计算结果产生较大影响，难以尽可能准确、全面地分析模型**

**思路**：在 “test_model 记录测试结果”和“准确率计算”两处分别设置概率阈值，进行筛选。在前者处筛选，可以将模型预测概率较低的内容筛选掉，可以排除模型的低质量预测结果、提高准确率；在后者处筛选，可以判断模型对两种图片的预测能力。



### 结果分析设计

在结果分析阶段，我们在跑一开始准备的由105个人的大头照组成的数据集时，遇到了比较严重的问题，就是用数据集测试的概率过低只有20%。

一开始我们决定提高训练轮数，但我们把轮数提高后，发现训练命中率明明很高了但是测试命中率的提高几乎微乎其微。

我们查阅相关资料发现，我们设计的模型出现了过拟合的情况。

我们便着手开始准备解决过拟合问题，尝试过如下操作：

1.给原有的CNN模型添加Dropingout层

2.修改原有的数据集，保持每个人物的图片数大体一致

3.调整模型的optimizer和loss

4.调试出适宜的训练轮数

经过以上方法的改良后，过拟合的情况得到有效的改善，但测试命中率提升仍然不明显。

我们开始思考是否是建立的keras模型本身的问题导致其无法处理过多的人物，我们便考虑缩减测试集模型的人物个数，测试命中率得到了有效的改善（具体详见结果分析）。